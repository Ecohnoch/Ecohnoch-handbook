# AdaBoost

定义，基学习器的线性组合：

$H(x) = \sum_{t=1}^{T}{\alpha_t h_t(x)}$

指数损失函数：

$\scl{l}_{exp}(H | \mathcal{D}) = \mathbb{E}_{x \sim \mathcal{D}}[e^{-f(x)H(x)}]$

训练流程：

* 1.初始

初始训练集：

$D =  \{(x_1, y_1), ..., (x_m, y_m)\}$

基学习算法(神经网络/决策树/...)：

$\mathfrak{L}$

初始数据集权重：

$\mathcal{D}_1(x) = \frac{1}{m}$

* 2.循环(1->t->T)根据误差计算分类器权重+更新数据权重分布

用基学习算法学习当前的学习器$h_t$：

$h_t = \mathfrak{L}(D, \mathcal{D}_t)$

计算当前学习器的误差：

$\epsilon_t = P_{x \sim \mathcal{D}_t}(h_t(x)\neq f(x))$

误差计算学习器的权重：

$\alpha_t = \frac{1}{2} \ln{\frac{1-\epsilon_t}{\epsilon_t}}$

更新数据权重分布：

$\mathcal{D}_{t+1}(x) = \frac{\mathcal{D}_t(x)}{Z_t} \times \left\{\begin{matrix}\exp{(-\alpha_t)}, & if\ h_t(x)=f(x) \\ \exp{(\alpha_t)}, & if\ h_t(x)\neq f(x) \end{matrix}\right.$

* 输出

$H(x) = sign(\sum_{t=1}^T{\alpha_t h_t(x)})$



# 附录

所有公式的latex写法：

```
H(x) = \sum_{t=1}^{T}{\alpha_t h_t(x)}

\scl{l}_{exp}(H | \mathcal{D}) = \mathbb{E}_{x \sim \mathcal{D}}[e^{-f(x)H(x)}]

D =  \{(x_1, y_1), ..., (x_m, y_m)\}

\mathfrak{L}

\mathcal{D}_1(x) = \frac{1}{m}

h_t = \mathfrak{L}(D, \mathcal{D}_t)

\epsilon_t = P_{x \sim \mathcal{D}_t}(h_t(x)\neq f(x))

\alpha_t = \frac{1}{2} \ln{\frac{1-\epsilon_t}{\epsilon_t}}

\mathcal{D}_{t+1}(x) = \frac{\mathcal{D}_t(x)}{Z_t} \times \left\{\begin{matrix}
\exp{(-\alpha_t)}, & if\ h_t(x)=f(x) \\ 
\exp{(\alpha_t)}, & if\ h_t(x)\neq f(x)
\end{matrix}\right.

H(x) = sign(\sum_{t=1}^T{\alpha_t h_t(x)})
```