# 向量加法GPU加速


```python
from numba import cuda
import numpy as np
import math
from time import time

@cuda.jit
def gpu_add(a, b, result, n):
    idx = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x
    if idx < n :
        result[idx] = a[idx] + b[idx]

def main():
    n = 20000000
    x = np.arange(n).astype(np.int32)
    y = 2 * x

    # 拷贝数据到设备端
    x_device = cuda.to_device(x)
    y_device = cuda.to_device(y)
    # 在显卡设备上初始化一块用于存放GPU计算结果的空间
    gpu_result = cuda.device_array(n)
    cpu_result = np.empty(n)

    threads_per_block = 1024
    blocks_per_grid = math.ceil(n / threads_per_block)
    start = time()
    gpu_add[blocks_per_grid, threads_per_block](x_device, y_device, gpu_result, n)
    cuda.synchronize()
    print("gpu vector add time " + str(time() - start))
    start = time()
    cpu_result = np.add(x, y)
    print("cpu vector add time " + str(time() - start))

    if (np.array_equal(cpu_result, gpu_result.copy_to_host())):
        print("result correct!")

if __name__ == "__main__":
    main()
```

增加声明哪些数据要拷贝到Device，哪些要返回Host，可以很快的加速。

# 数据拷贝到Device

```python
arr = np.arange(10)
device_arr = cuda.to_device(arr)
```

# 返回到Host

```python
host_arr = device_arr.copy_to_host()
```

# CUDA编程流程

1. 初始化，拷贝数据到GPU Device
2. 按配置执行，并行调用CUDA核函数
3. CPU和GPU异步计算
4. GPU将结果返回Host

# Source

[[1] https://zhuanlan.zhihu.com/p/77307505](https://zhuanlan.zhihu.com/p/77307505)

